package main.scala


import org.apache.spark.streaming.Seconds
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.streaming.StreamingContext._
import org.apache.spark.rdd.RDD
import org.apache.spark.SparkContext._
import java.io.{File, PrintWriter}


//import twitter4j._
//import twitter4j.auth.Authorization
//import java.util.prefs.Preferences
//import twitter4j.conf.ConfigurationBuilder
//import twitter4j.conf.PropertyConfiguration
//import twitter4j.auth.OAuthAuthorization
//import twitter4j.auth.AccessToken
import org.apache.spark.HashPartitioner

/**
 * Counts words in UTF8 encoded, '\n' delimited text received from the network every second.
 * Usage: NetworkWordCount <master> <hostname> <port>
 *   <master> is the Spark master URL. In local mode, <master> should be 'local[n]' with n > 1.
 *   <hostname> and <port> describe the TCP server that Spark Streaming would connect to receive data.
 *
 * To run this on your local machine, you need to first run a Netcat server
 *    `$ nc -lk 9999`
 * and then run the example
 *    `$ ./run spark.streaming.examples.NetworkWordCount local[2] localhost 9999`
 */
object NetworkTest {
  def main(args: Array[String]) {
    if (args.length < 3) {
      System.err.println("Usage: NetworkWordCount <master> <hostname> <port>\n" +
        "In local mode, <master> should be 'local[n]' with n > 1")
      System.exit(1)
    }

    // Create the context with a 1 second batch size
    val ssc = new StreamingContext(args(0), "NetworkTest", Seconds(args(2).toInt),
      System.getenv("SPARK_HOME"), Seq(System.getenv("SPARK_EXAMPLES_JAR")))

    // Create a NetworkInputDStream on target ip:port and count the
    // words in input stream of \n delimited test (eg. generated by 'nc') 

    //ssc.checkpointDuration = Seconds(999999)

    val x = ssc.socketTextStream(args(1), 9999).map(_.split(",")).map(arr => (arr(0).toInt,arr(1).toInt))
    val y = ssc.socketTextStream(args(1), 9998).map(_.split(",")).map(arr => (arr(0).toInt,arr(1).toInt))
    //val z = ssc.socketTextStream(args(1), 9997)

    val xx = x.window(Seconds(10))
    val yy = y.window(Seconds(10))

    val gb = x.combineByKey[Int](s => 1, (c,s) => (c+1), (c1,c2) => (c1+c2), new HashPartitioner(ssc.sparkContext.defaultParallelism))

    gb.print()

    //z.window(Seconds(1000)).count.print()

//    val conf = new ConfigurationBuilder()
//    conf.setOAuthConsumerKey("ELMGMO39Ao2xtR6eVFWB7A")
//    conf.setOAuthConsumerSecret("3HE6G6Nf92nknVvmcaOFugKPT90Er6LnNwP4RvI")
//    conf.setOAuthAccessToken("46639229-c9OGp8vgFRSkpWKfTodTlq1bR8mH8drTNv6Ma55Ni")
//    conf.setOAuthAccessTokenSecret("I0b70CwaQizXUtupo7hFCgidTaarqJ8FkvSBAymyhlaUG")
//
//    val auth = new OAuthAuthorization(conf.build)
//    val stream = ssc.twitterStream(Some(auth))
//    stream.count.print()




    //    val wordCounts = words.window(Seconds(10),Seconds(1)).map(x => (x, 1)).reduceByKey(_ + _)
//    val words2 = lines.flatMap(_.split(" ")).filter(_.contains("b"))
//    val wordCounts2 = words2.window(Seconds(10),Seconds(1)).map(x => (x, 2)).reduceByKey(_ + _)
    //wordCounts.print()
    //wordCounts2.print()
//    val jj = wordCounts.cogroup(wordCounts2)
//    jj.print()




    ssc.start()
  }
}
